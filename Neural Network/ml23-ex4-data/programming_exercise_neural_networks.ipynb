{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "GROUP = \"04\"  # TODO: write in your group number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From last exercise sheet\n",
    "def load_feature_vectors(filename: str) -> np.array:\n",
    "    \"\"\"\n",
    "    Load the feature vectors from the dataset in the given file and return\n",
    "    them as a numpy array with shape (number-of-examples, number-of-features + 1).\n",
    "    \"\"\"\n",
    "    #features = pd.read_csv(filename, sep='\\t', usecols=[\"#id\", \"chars_count\"]).to_numpy()\n",
    "    features = pd.read_csv(filename, sep='\\t').to_numpy()\n",
    "    features[:, 0] = 1 # replace #id column with w0\n",
    "    return features.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From last exercise sheet\n",
    "def load_class_values(filename: str) -> np.array:\n",
    "    \"\"\"\n",
    "    Load the class values for overall quality (class 0 for quality 1 and class 1\n",
    "    for overall quality 2 or 3) from the dataset in the given file and return\n",
    "    them as a one-dimensional numpy array.\n",
    "    \"\"\"\n",
    "    return np.ravel((pd.read_csv(filename, sep='\\t', usecols=[\"overall quality\"]).to_numpy() > 1) * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = load_feature_vectors('features-train-cleaned.tsv')\n",
    "test_features = load_feature_vectors('features-test-cleaned.tsv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_class_values(cs: list[str], class_index: dict[str, int]) -> np.array:\n",
    "    \"\"\"\n",
    "    Encode the given list of given class values as one-hot vectors.\n",
    "\n",
    "    Arguments:\n",
    "    - cs: a list of n class values from a dataset\n",
    "    - class_index: a dictionary that maps each class value to a number between\n",
    "         0 and k-1, where k is the number of distinct classes.\n",
    "\n",
    "    Returns:\n",
    "    - an array of shape (n, k) containing n column vectors with k elements each.\n",
    "    \"\"\"\n",
    "    k = len(class_index)\n",
    "    n = len(cs)\n",
    "    encoded_array = np.zeros((n, k), dtype=int)\n",
    "\n",
    "    for i, value in enumerate(cs):\n",
    "        encoded_array[i, class_index[value]] = 1\n",
    "\n",
    "    return encoded_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# Assuming class_index is a dictionary mapping class values to indices\n",
    "class_index = {'class1': 0, 'class2': 1, 'class3': 2}\n",
    "class_values = ['class1', 'class2', 'class3', 'class1', 'class3']\n",
    "\n",
    "encoded_values = encode_class_values(class_values, class_index)\n",
    "print(encoded_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def misclassification_rate(cs: np.array, ys: np.array) -> float:\n",
    "    \"\"\"\n",
    "    This function takes two vectors with gold and predicted labels and\n",
    "    returns the percentage of positions where truth and prediction disagree\n",
    "    \"\"\"\n",
    "    if len(cs) == 0:\n",
    "        return float('nan')\n",
    "    else:\n",
    "        hits = [cs[i][ys[i]] for i in range(len(ys))]\n",
    "        return 1 - (sum(hits) / len(ys))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From code linked on lecture slide\n",
    "def initialize_random_weights(p: int, l: int, k: int) -> Tuple[np.array, np.array]:\n",
    "    \"\"\"\n",
    "    Initialize the weight matrices of a two-layer MLP.\n",
    "\n",
    "    Arguments:\n",
    "    - `p`: number of input attributes\n",
    "    - `l`: number of hidden layer features\n",
    "    - `k`: number of output classes\n",
    "\n",
    "    Returns:\n",
    "    - W_h, a l-by-(p+1) matrix\n",
    "    - W_o, a k-by-(l+1) matrix\n",
    "    \"\"\"\n",
    "    W_h = np.random.normal(size=(l, p+1))\n",
    "    W_o = np.random.normal(size=(k, l+1))\n",
    "    return W_h, W_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From code linked on lecture slide / last exercise sheet\n",
    "def sigmoid(z: np.array) -> np.array:\n",
    "    return 1 / (1 + np.exp(np.clip(-z, -30, 30)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_probabilities(W_h: np.array, W_o: np.array, xs: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Predict the class probabilities for each example in xs.\n",
    "\n",
    "    Arguments:\n",
    "    - `W_h`: a l-by-(p+1) matrix\n",
    "    - `W_o`: a k-by-(l+1) matrix\n",
    "    - `xs`: feature vectors in the dataset as a two-dimensional numpy array\n",
    "            with shape (n, p+1)\n",
    "\n",
    "    Returns:\n",
    "    - The probabilities for each of the k classes for each of the n examples as\n",
    "      a two-dimensional numpy array with shape (n, k)\n",
    "    \"\"\"\n",
    "    # Add bias term to input features\n",
    "    xs_with_bias = np.column_stack((np.ones(len(xs)), xs))\n",
    "    \n",
    "    # Calculate hidden layer outputs\n",
    "    z_h = np.dot(W_h, xs_with_bias.T)\n",
    "    a_h = sigmoid(z_h)\n",
    "\n",
    "    # Add bias term to hidden layer outputs\n",
    "    a_h_with_bias = np.row_stack((np.ones(len(a_h[0])), a_h))\n",
    "\n",
    "    # Calculate output layer inputs\n",
    "    z_o = np.dot(W_o, a_h_with_bias)\n",
    "\n",
    "    # Calculate output layer probabilities using sigmoid activation\n",
    "    a_o = sigmoid(z_o).T\n",
    "\n",
    "    return a_o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(W_h: np.array, W_o: np.array, xs: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Predict the class for each example in xs.\n",
    "\n",
    "    Arguments:\n",
    "    - `W_h`: a l-by-(p+1) matrix\n",
    "    - `W_o`: a k-by-(l+1) matrix\n",
    "    - `xs`: feature vectors in the dataset as a two-dimensional numpy array\n",
    "            with shape (n, p+1)\n",
    "\n",
    "    Returns:\n",
    "    - The predicted class for each of the n examples as an array of length n\n",
    "    \"\"\"\n",
    "    # Get class probabilities\n",
    "    probabilities = predict_probabilities(W_h, W_o, xs)\n",
    "    \n",
    "    # Return the class with the highest probability for each example\n",
    "    return np.argmax(probabilities, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multilayer_perceptron(xs: np.array, cs: np.array, l: int, eta: float=0.0001, iterations: int=1000, validation_fraction: float=0) -> Tuple[list[Tuple[np.array, np.array]], list[float], list[float]]:\n",
    "    \"\"\"\n",
    "    Fit a multilayer perceptron with two layers and return the learned weight matrices as numpy arrays.\n",
    "\n",
    "    Arguments:\n",
    "    - `xs`: feature vectors in the training dataset as a two-dimensional numpy array with shape (n, p+1)\n",
    "    - `cs`: class values for every element in `xs` as a two-dimensional numpy array with shape (n, k)\n",
    "    - `l`: the number of hidden layer features\n",
    "    - `eta`: the learning rate as a float value\n",
    "    - `iterations': the number of iterations to run the algorithm for\n",
    "    - 'validation_fraction': fraction of xs and cs used for validation (not for training)\n",
    "\n",
    "    Returns:\n",
    "    - models (W_h, W_o) for each iteration, where W_h is a l-by-(p+1) matrix and W_o is a k-by-(l+1) matrix\n",
    "    - misclassification rate of predictions on training part of xs/cs for each iteration\n",
    "    - misclassification rate of predictions on validation part of xs/cs for each iteration\n",
    "    \"\"\"\n",
    "    models = []\n",
    "    train_misclassification_rates = []\n",
    "    validation_misclassification_rates = []\n",
    "    last_train_index = round((1 - validation_fraction) * len(cs))\n",
    "\n",
    "    p = len(xs[0]) - 1\n",
    "    k = len(cs[0])\n",
    "    W_h, W_o = initialize_random_weights(p, l, k)\n",
    "\n",
    "    for t in range(iterations):\n",
    "        for i in range(last_train_index):\n",
    "            x = np.reshape(xs[i], (len(xs[i]), 1))\n",
    "            c = cs[i].reshape(k, 1)\n",
    "    \n",
    "            # Forward pass\n",
    "            xs_with_bias = np.row_stack((np.ones(1), x))\n",
    "            z_h = np.dot(W_h, xs_with_bias)\n",
    "            a_h = sigmoid(z_h)\n",
    "            \n",
    "            a_h_with_bias = np.row_stack((np.ones(1), a_h))\n",
    "            z_o = np.dot(W_o, a_h_with_bias)\n",
    "            a_o = sigmoid(z_o)\n",
    "            \n",
    "            # Backward pass\n",
    "            delta_o = a_o - c\n",
    "            delta_h = np.dot(W_o.T, delta_o) * a_h_with_bias * (1 - a_h_with_bias)\n",
    "\n",
    "            # Update weights\n",
    "            W_o -= eta * np.dot(delta_o, a_h_with_bias.T)\n",
    "            W_h -= eta * np.dot(delta_h[1:], xs_with_bias.T)\n",
    "\n",
    "        models.append((W_h.copy(), W_o.copy()))\n",
    "        train_misclassification_rates.append(misclassification_rate(cs[0:last_train_index,:], predict(W_h, W_o, xs[0:last_train_index,:])))\n",
    "        validation_misclassification_rates.append(misclassification_rate(cs[last_train_index:,:], predict(W_h, W_o, xs[last_train_index:,:])))\n",
    "\n",
    "    return models, train_misclassification_rates, validation_misclassification_rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From last exercise sheet\n",
    "def plot_misclassification_rates(train_misclassification_rates: List[float], validation_misclassification_rates: List[float], save_path: str = None):\n",
    "    \"\"\"\n",
    "    Plots both misclassification rates for each iteration.\n",
    "    \"\"\"\n",
    "    plt.plot(train_misclassification_rates, label=\"Misclassification rate (train)\")\n",
    "    plt.plot(validation_misclassification_rates, label=\"Misclassification rate (validation)\")\n",
    "    plt.legend()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    else:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 91\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m     90\u001b[0m train_features_file_name \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39margv[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 91\u001b[0m train_classes_file_name \u001b[38;5;241m=\u001b[39m \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     92\u001b[0m test_features_file_name \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39margv[\u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m     93\u001b[0m test_predictions_file_name \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39margv[\u001b[38;5;241m4\u001b[39m]\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# Tests\n",
    "import os\n",
    "from pytest import approx\n",
    "\n",
    "def test_encode_class_values():\n",
    "    cs = ['red', 'green', 'red', 'blue', 'green']\n",
    "    class_index = {'red': 0, 'green': 1, 'blue': 2}\n",
    "\n",
    "    expected = np.array([\n",
    "        [1, 0, 0],\n",
    "        [0, 1, 0],\n",
    "        [1, 0, 0],\n",
    "        [0, 0, 1],\n",
    "        [0, 1, 0],\n",
    "    ])\n",
    "\n",
    "    actual = encode_class_values(cs, class_index)\n",
    "\n",
    "    assert actual.shape == (5, 3), \"encode_class_values should return array of shape (n, k).\"\n",
    "\n",
    "    assert actual.dtype == int, \"encode_class_values should return an integer array.\"\n",
    "\n",
    "    assert np.all(expected == actual), \\\n",
    "        \"encode_class_values should return (n, k, 1)-array of one-hot vectors.\"\n",
    "\n",
    "def test_predict_proabilities():\n",
    "    class_index = {'red': 0, 'green': 1, 'blue': 2}\n",
    "    cs = encode_class_values(['red', 'green', 'red', 'blue', 'green'], class_index)\n",
    "    xs = np.array([\n",
    "        [1, 1, 0, 0],\n",
    "        [1, 0, 1, 0],\n",
    "        [1, 1, 0, 0.5],\n",
    "        [1, 0, 0, 1],\n",
    "        [1, 0, 1, 0.5]\n",
    "    ])\n",
    "    p = len(xs[0]) - 1\n",
    "    k = len(cs[0])\n",
    "    W_h, W_o = initialize_random_weights(p, 8, k)\n",
    "\n",
    "    probabilities = predict_probabilities(W_h, W_o, xs)\n",
    "    assert probabilities.shape == (len(xs), k), \\\n",
    "        \"predict_probabilities should return a shape of (n, k)\"\n",
    "\n",
    "def test_predict():\n",
    "    class_index = {'red': 0, 'green': 1, 'blue': 2}\n",
    "    cs = encode_class_values(['red', 'green', 'red', 'blue', 'green'], class_index)\n",
    "    xs = np.array([\n",
    "        [1, 1, 0, 0],\n",
    "        [1, 0, 1, 0],\n",
    "        [1, 1, 0, 0.5],\n",
    "        [1, 0, 0, 1],\n",
    "        [1, 0, 1, 0.5]\n",
    "    ])\n",
    "    p = len(xs[0]) - 1\n",
    "    k = len(cs[0])\n",
    "    W_h, W_o = initialize_random_weights(p, 8, k)\n",
    "\n",
    "    ys = predict(W_h, W_o, xs)\n",
    "    assert ys.shape == (len(xs), ), \\\n",
    "        \"predict should return a shape of (n, )\"\n",
    "\n",
    "def test_train():\n",
    "    class_index = {'red': 0, 'green': 1, 'blue': 2}\n",
    "    cs = encode_class_values(['red', 'green', 'red', 'blue', 'green'], class_index)\n",
    "    xs = np.array([\n",
    "        [1, 1, 0, 0],\n",
    "        [1, 0, 1, 0],\n",
    "        [1, 1, 0, 0.5],\n",
    "        [1, 0, 0, 1],\n",
    "        [1, 0, 1, 0.5]\n",
    "    ])\n",
    "    models, _, _ = train_multilayer_perceptron(xs, cs, 2, eta=1, iterations=100, validation_fraction=0.4)\n",
    "    W_h, W_o = models[-1] # get last model\n",
    "\n",
    "    y = predict(W_h, W_o, np.array([[1, 1, 0, 0.2]]))\n",
    "    assert y == class_index['red'], \\\n",
    "        \"fit should learn a simple classification problem\"\n",
    "\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# Main program for running against the training dataset\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import pandas as pd\n",
    "    import pytest\n",
    "    import sys\n",
    "\n",
    "    train_features_file_name = sys.argv[1]\n",
    "    train_classes_file_name = sys.argv[2]\n",
    "    test_features_file_name = sys.argv[3]\n",
    "    test_predictions_file_name = sys.argv[4]\n",
    "\n",
    "    xs = load_feature_vectors(train_features_file_name)\n",
    "    xs_test = load_feature_vectors(test_features_file_name)\n",
    "\n",
    "    print(\"(a)\")\n",
    "    test_a_result = pytest.main(['-k', 'test_encode_class_values', '--tb=short', __file__])\n",
    "    if test_a_result != 0:\n",
    "        sys.exit(test_a_result)\n",
    "    print(\"Test encode_class_values function successful\")\n",
    "\n",
    "    # encode class \"0\" as [1 0] and class \"1\" as [0 1]\n",
    "    class_index = {0: 0, 1: 1}\n",
    "    cs = encode_class_values(load_class_values(train_classes_file_name), class_index)\n",
    "\n",
    "    print(\"(b)\")\n",
    "    test_b_result = pytest.main(['-k', 'test_predict_proabilities', '--tb=short', __file__])\n",
    "    if test_b_result != 0:\n",
    "        sys.exit(test_b_result)\n",
    "    print(\"Test predict_probabilities function successful\")\n",
    "\n",
    "    print(\"(c)\")\n",
    "    test_c_result = pytest.main(['-k', 'test_predict', '--tb=short', __file__])\n",
    "    if test_c_result != 0:\n",
    "        sys.exit(test_c_result)\n",
    "    print(\"Test predict function successful\")\n",
    "\n",
    "    print(\"(d)\")\n",
    "    test_d_result = pytest.main(['-k', 'test_train', '--tb=short', __file__])\n",
    "    if test_d_result != 0:\n",
    "        sys.exit(test_d_result)\n",
    "    print(\"Test train_multilayer_perceptron function successful\")\n",
    "    models, train_misclassification_rates, validation_misclassification_rates = train_multilayer_perceptron(xs, cs, 16, eta=0.001, iterations=300, validation_fraction=0.2)\n",
    "    plot_misclassification_rates(train_misclassification_rates, validation_misclassification_rates)\n",
    "\n",
    "    print(\"(e)\")\n",
    "    best_model_index = np.argmin(validation_misclassification_rates)\n",
    "    print(\"Minimal misclassification rate on validation set (index \" + str(best_model_index) + \"): \" + str(validation_misclassification_rates[best_model_index]))\n",
    "    W_h, W_o = models[best_model_index]\n",
    "    y_test = predict(W_h, W_o, xs_test)\n",
    "    np.savetxt(test_predictions_file_name, y_test, fmt='%d', delimiter='\\t', newline='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
